@inproceedings{bulej2019initial,
  title        = {Initial experiments with duet benchmarking: Performance testing interference in the cloud},
  author       = {Bulej, Lubom{\'\i}r and Hork{\`y}, Vojt{\v{e}}ch and T{\uu}ma, Petr},
  booktitle    = {2019 IEEE 27th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)},
  pages        = {249--255},
  year         = {2019},
  organization = {IEEE}
}

@inproceedings{bulej2020duet,
  title     = {Duet benchmarking: improving measurement accuracy in the cloud},
  author    = {Bulej, Lubom{\'\i}r and Hork{\`y}, Vojt{\v{e}}ch and Tuma, Petr and Farquet, Fran{\c{c}}ois and Prokopec, Aleksandar},
  booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
  pages     = {100--107},
  year      = {2020}
}

@inproceedings{abedi2017conducting,
  title     = {Conducting repeatable experiments in highly variable cloud computing environments},
  author    = {Abedi, Ali and Brecht, Tim},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
  pages     = {287--292},
  year      = {2017}
}

@article{laaber2019software,
  title     = {Software microbenchmarking in the cloud. How bad is it really?},
  author    = {Laaber, Christoph and Scheuner, Joel and Leitner, Philipp},
  journal   = {Empirical Software Engineering},
  volume    = {24},
  number    = {4},
  pages     = {2469--2508},
  year      = {2019},
  publisher = {Springer}
}

@article{leitner2016patterns,
  title     = {Patterns in the chaosâ€”a study of performance variation and predictability in public iaas clouds},
  author    = {Leitner, Philipp and Cito, J{\"u}rgen},
  journal   = {ACM Transactions on Internet Technology (TOIT)},
  volume    = {16},
  number    = {3},
  pages     = {1--23},
  year      = {2016},
  publisher = {ACM New York, NY, USA}
}




@inproceedings{scheuner2018estimating,
  title        = {Estimating cloud application performance based on micro-benchmark profiling},
  author       = {Scheuner, Joel and Leitner, Philipp},
  booktitle    = {2018 IEEE 11th International Conference on Cloud Computing (CLOUD)},
  pages        = {90--97},
  year         = {2018},
  organization = {IEEE}
}

@article{shankar2018measuring,
  title     = {Measuring performance variability in the clouds},
  author    = {Shankar, Shiv and Acken, John M and Sehgal, Naresh K},
  journal   = {IETE Technical Review},
  volume    = {35},
  number    = {6},
  pages     = {656--660},
  year      = {2018},
  publisher = {Taylor \& Francis}
}

@inproceedings{uta2020big,
  title     = {Is big data performance reproducible in modern cloud networks?},
  author    = {Uta, Alexandru and Custura, Alexandru and Duplyakin, Dmitry and Jimenez, Ivo and Rellermeyer, Jan and Maltzahn, Carlos and Ricci, Robert and Iosup, Alexandru},
  booktitle = {17th USENIX symposium on networked systems design and implementation (NSDI 20)},
  pages     = {513--527},
  year      = {2020}
}

@inproceedings{oliveira2017perphecy,
  title     = {Perphecy: Performance Regression Test Selection Made Simple but Effective},
  booktitle = {Proc. of the 10th IEEE International Conference on Software Testing, Verification and Validation (ICST)},
  year      = {2017},
  address   = {Tokyo, Japan},
  abstract  = {<p>Developers of performance sensitive production software are in a dilemma: performance regression tests are too costly to run at each commit, but skipping the tests delays and complicates performance regression detection. Ideally, developers would have a system that predicts whether a given commit is likely to impact performance and suggests which tests to run to detect a potential performance regression. Prior approaches towards this problem require static or dynamic analyses that limit their generality and applicability. This paper presents an approach that is simple and general, and that works surprisingly well for real applications.</p> },
  author    = {Augusto Oliveira and Sebastian Fischmeister and Amer Diwan and Matthias Hauswirth and Peter Sweeney}
}